{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation: using python to sweep over methods and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we illustrate how to use python to generate and run a list of commands. In this example, we generate a list of QIIME 1.9.0 ``assign_taxonomy.py`` commands, though this workflow for command generation is generally very useful for performing *parameter sweeps* (i.e., exploration of sets of parameters for achieving a specific result for comparative purposes). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggmap is custome code from Stefan Janssen, download at https://github.com/sjanssen2/ggmap\n",
      "Reading settings file '/home/sjanssen/.ggmaprc'\n"
     ]
    }
   ],
   "source": [
    "from os import system, environ\n",
    "from os.path import join, expandvars \n",
    "from joblib import Parallel, delayed\n",
    "from glob import glob\n",
    "from tax_credit.framework_functions import (recall_novel_taxa_dirs,\n",
    "                                            parameter_sweep,\n",
    "                                            move_results_to_repository)\n",
    "from ggmap.snippets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"../..\"\n",
    "analysis_name= \"novel-taxa-simulations\"\n",
    "\n",
    "results_dir = join('..', '..', 'novel-taxa-tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data set sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we're going to define the data sets that we'll sweep over. As the simulated novel taxa dataset names depend on how the database generation notebook was executed, we must define the variables used to create these datasets. If you modified any variables in that notebook, set these same variables below. If you did not, then do not modify.\n",
    "\n",
    "recall_novel_taxa_dirs() generates a list of dataset_reference_combinations and a dictionary of reference_dbs mapped to each dataset, which we feed to parameter_sweep below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "data_dir = join(project_dir, \"data\", analysis_name)\n",
    "# databases is a list of names given as dictionary keys in the second\n",
    "# cell of the database generation notebook. Just list the names here.\n",
    "databases = ['B1-REF']\n",
    "\n",
    "# Generate a list of input directories\n",
    "(dataset_reference_combinations, reference_dbs) = recall_novel_taxa_dirs(data_dir, databases, iterations, min_level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the method/parameter combinations and generating commands\n",
    "\n",
    "Now we set the methods and method-specific parameters that we want to sweep. Modify to sweep other methods. Note how method_parameters_combinations feeds method/parameter combinations to parameter_sweep() in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_parameters_combinations = {\n",
    "    'sepp-paths': {'method': ['path'], 'reference_name': ['gg138']},\n",
    "    'sepp-otus': {'method': ['otus'], 'reference_name': ['gg138']}\n",
    "}\n",
    "\n",
    "# this filepath needs to point to the directory in which the SEPP wrapper can be found\n",
    "fp_wrapper_script = '../../../q2-fragment-insertion/tax-credit/'\n",
    "\n",
    "#command_template = 'bash -c \"source activate qiime1; source ./.bashrc; mkdir -p {0} ; assign_taxonomy.py -v -i {1} -o {0} -r {2} -t {3} -m {4} {5} --rdp_max_memory 16000\"'\n",
    "command_template = '%s/wrapper_sepp.py {1} {0}/query_tax_assignments.txt --novel_taxa_keep {2} --novel_taxa_level `echo \"{1}\" | sed \"s#^.*-L##\" | sed \"s/-iter.*$//\"` {5}' % fp_wrapper_script\n",
    "\n",
    "command_template += ' --reference_alignment %s --reference_phylogeny %s' % (\n",
    "    join(environ['CONDA_PREFIX'], 'share', 'fragment-insertion', 'ref', 'gg_13_5_ssu_align_99_pfiltered.fasta'),\n",
    "    join(environ['CONDA_PREFIX'], 'share', 'fragment-insertion', 'ref', 'reference-gg-raxml-bl-rooted-relabelled.tre'))\n",
    "\n",
    "commands = parameter_sweep(data_dir, results_dir, reference_dbs,\n",
    "                           dataset_reference_combinations,\n",
    "                           method_parameters_combinations, command_template,\n",
    "                           infile='query.fasta', output_name='query_tax_assignments.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can look at the first command that was generated and the number of commands generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepp-otus\n",
      "../../../q2-fragment-insertion/tax-credit//wrapper_sepp.py ../../data/novel-taxa-simulations/B1-REF-L6-iter5/query.fasta ../../novel-taxa-tmp/B1-REF-L6-iter5/B1-REF-L6-iter5/sepp-otus/otus:gg138/query_tax_assignments.txt --novel_taxa_keep ../../data/novel-taxa-simulations/B1-REF-L6-iter5/ref_seqs.fasta --novel_taxa_level `echo \"../../data/novel-taxa-simulations/B1-REF-L6-iter5/query.fasta\" | sed \"s#^.*-L##\" | sed \"s/-iter.*$//\"` --method otus --reference_name gg138 --reference_alignment /home/sjanssen/miniconda3/envs/qiime2-2018.6/share/fragment-insertion/ref/gg_13_5_ssu_align_99_pfiltered.fasta --reference_phylogeny /home/sjanssen/miniconda3/envs/qiime2-2018.6/share/fragment-insertion/ref/reference-gg-raxml-bl-rooted-relabelled.tre\n",
      "sepp-paths\n"
     ]
    }
   ],
   "source": [
    "for method in method_parameters_combinations:\n",
    "    print(method)\n",
    "    for command in commands:\n",
    "        if '/'+method+'/' in command:\n",
    "            print(command)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(commands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run our commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=23)(delayed(system)(command) for command in commands);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source activate qiime2-2018.6; echo '../../../q2-fragment-insertion/tax-credit//wrapper_sepp.py ../../data/novel-taxa-simulations/B1-REF-L6-iter5/query.fasta ../../novel-taxa-tmp/B1-REF-L6-iter5/B1-REF-L6-iter5/sepp-otus/otus:gg138/query_tax_assignments.txt --novel_taxa_keep ../../data/novel-taxa-simulations/B1-REF-L6-iter5/ref_seqs.fasta --novel_taxa_level `echo \"../../data/novel-taxa-simulations/B1-REF-L6-iter5/query.fasta\" | sed \"s#^.*-L##\" | sed \"s/-iter.*$//\"` --method otus --reference_name gg138 --reference_alignment /home/sjanssen/miniconda3/envs/qiime2-2018.6/share/fragment-insertion/ref/gg_13_5_ssu_align_99_pfiltered.fasta --reference_phylogeny /home/sjanssen/miniconda3/envs/qiime2-2018.6/share/fragment-insertion/ref/reference-gg-raxml-bl-rooted-relabelled.tre' | /opt/torque-4.2.8/bin/qsub -d '/home/sjanssen/miniconda3/envs/qiime2-2018.6/src/tax-credit-data/ipynb/novel-taxa' -V -l walltime=4:00:00,nodes=1:ppn=20,pmem=8GB -N cr_taxcredit_sepp_0 -t 1-1 \n"
     ]
    }
   ],
   "source": [
    "for i, cmd in enumerate(sorted(commands)):\n",
    "    cluster_run([cmd], 'taxcredit_sepp_%i' % i, \"./dummy\", environment='qiime2-2018.6', ppn=20,\n",
    "                wait=False, dry=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Using QIIME 1 or Command-Line Classifiers\n",
    "\n",
    "Here we provide an example of taxonomy assignment using legacy ``QIIME 1`` classifiers executed on the command line. To accomplish this, we must first convert ``commands`` to a string, which we then pass to bash for execution. As ``QIIME 1`` is written in python-2, we must also activate a separate environment in which QIIME 1 [has been installed](http://qiime.org/install/install.html). If any environmental variables need to be set (in this example, the [RDP_JAR_PATH](http://qiime.org/install/alternative.html#rdp-jar-path-environment-variable)), we must also source the .bashrc file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_parameters_combinations = { # probabalistic classifiers\n",
    "              'rdp': {'confidence': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
    "                                     0.6, 0.7, 0.8, 0.9, 1.0]},\n",
    "              \n",
    "              # global alignment classifiers\n",
    "              'uclust': {'min_consensus_fraction': [0.51, 0.76, 1.0], \n",
    "                         'similarity': [0.8, 0.9],\n",
    "                         'uclust_max_accepts': [1, 3, 5]},\n",
    "             \n",
    "              # local alignment classifiers\n",
    "              'sortmerna': {'sortmerna_e_value': [1.0],\n",
    "                            'min_consensus_fraction': [0.51, 0.76, 1.0], \n",
    "                            'similarity': [0.8, 0.9],\n",
    "                            'sortmerna_best_N_alignments ': [1, 3, 5],\n",
    "                            'sortmerna_coverage' : [0.8, 0.9]},\n",
    "              'blast' : {'blast_e_value' : [0.0000000001, 0.001, 1, 1000]}\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now enter the template of the command to sweep, and generate a list of commands with ``parameter_sweep()``.\n",
    "\n",
    "Fields must adhere to following format:\n",
    "\n",
    "                      {0} = output directory\n",
    "                      {1} = input data\n",
    "                      {2} = output destination\n",
    "                      {3} = reference taxonomy\n",
    "                      {4} = method name\n",
    "                      {5} = other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "command_template = 'bash -c \"source activate qiime1; source ./.bashrc; mkdir -p {0} ; assign_taxonomy.py -v -i {1} -o {0} -r {2} -t {3} -m {4} {5} --rdp_max_memory 16000\"'\n",
    "\n",
    "commands = parameter_sweep(data_dir, results_dir, reference_dbs,\n",
    "                           dataset_reference_combinations,\n",
    "                           method_parameters_combinations, command_template,\n",
    "                           infile='query.fasta', output_name='query_tax_assignments.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can look at the first command that was generated and the number of commands generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sortmerna\n",
      "bash -c \"source activate qiime1; source ./.bashrc; mkdir -p ../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/sortmerna/0.51:0.8:1:0.8:1.0 ; assign_taxonomy.py -v -i ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.fasta -o ../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/sortmerna/0.51:0.8:1:0.8:1.0 -r ../../data/novel-taxa-simulations/B1-REF-L6-iter0/ref_seqs.fasta -t ../../data/novel-taxa-simulations/B1-REF-L6-iter0/ref_taxa.tsv -m sortmerna --sortmerna_e_value 1.0 --min_consensus_fraction 0.51 --similarity 0.8 --sortmerna_best_N_alignments  1 --sortmerna_coverage 0.8 --rdp_max_memory 16000\"\n",
      "uclust\n",
      "bash -c \"source activate qiime1; source ./.bashrc; mkdir -p ../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/uclust/0.51:0.8:1 ; assign_taxonomy.py -v -i ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.fasta -o ../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/uclust/0.51:0.8:1 -r ../../data/novel-taxa-simulations/B1-REF-L6-iter0/ref_seqs.fasta -t ../../data/novel-taxa-simulations/B1-REF-L6-iter0/ref_taxa.tsv -m uclust --min_consensus_fraction 0.51 --similarity 0.8 --uclust_max_accepts 1 --rdp_max_memory 16000\"\n",
      "rdp\n",
      "bash -c \"source activate qiime1; source ./.bashrc; mkdir -p ../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/rdp/0.0 ; assign_taxonomy.py -v -i ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.fasta -o ../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/rdp/0.0 -r ../../data/novel-taxa-simulations/B1-REF-L6-iter0/ref_seqs.fasta -t ../../data/novel-taxa-simulations/B1-REF-L6-iter0/ref_taxa.tsv -m rdp --confidence 0.0 --rdp_max_memory 16000\"\n",
      "blast\n",
      "bash -c \"source activate qiime1; source ./.bashrc; mkdir -p ../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/blast/1e-10 ; assign_taxonomy.py -v -i ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.fasta -o ../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/blast/1e-10 -r ../../data/novel-taxa-simulations/B1-REF-L6-iter0/ref_seqs.fasta -t ../../data/novel-taxa-simulations/B1-REF-L6-iter0/ref_taxa.tsv -m blast --blast_e_value 1e-10 --rdp_max_memory 16000\"\n"
     ]
    }
   ],
   "source": [
    "for method in method_parameters_combinations:\n",
    "    print(method)\n",
    "    for command in commands:\n",
    "        if '/'+method+'/' in command:\n",
    "            print(command)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8280\n"
     ]
    }
   ],
   "source": [
    "print(len(commands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run our commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=23)(delayed(system)(command) for command in commands);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLAST+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(dataset_reference_combinations, reference_dbs) = recall_novel_taxa_dirs(\n",
    "    data_dir, databases, iterations, ref_seqs='ref_seqs.qza', ref_taxa='ref_taxa.qza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_parameters_combinations = {\n",
    "              'blast+' : {'p-evalue': [0.001],\n",
    "                          'p-maxaccepts': [1, 10],\n",
    "                          'p-perc-identity': [0.80, 0.97, 0.99],\n",
    "                          'p-min-consensus': [0.51, 0.75, 0.99]}\n",
    "             }\n",
    "\n",
    "command_template = (\"mkdir -p {0}; \"\n",
    "                    \"qiime feature-classifier classify-consensus-blast --i-query {1} --o-classification \"\n",
    "                    \"{0}/rep_seqs_tax_assignments.qza --i-reference-reads {2} --i-reference-taxonomy {3} {5}; \"\n",
    "                    \"qiime tools export {0}/rep_seqs_tax_assignments.qza --output-dir {0}; \"\n",
    "                    \"mv {0}/taxonomy.tsv {0}/query_tax_assignments.txt\")\n",
    "        \n",
    "\n",
    "commands = parameter_sweep(data_dir, results_dir, reference_dbs,\n",
    "                           dataset_reference_combinations,\n",
    "                           method_parameters_combinations, command_template,\n",
    "                           infile='query.qza', output_name='rep_seqs_tax_assignments.qza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=23)(delayed(system)(command) for command in commands);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_parameters_combinations = {\n",
    "              'vsearch' : {'p-maxaccepts': [1, 10],\n",
    "                           'p-perc-identity': [0.80, 0.90, 0.97, 0.99],\n",
    "                           'p-min-consensus': [0.51, 0.99]}\n",
    "             }\n",
    "\n",
    "command_template = (\"mkdir -p {0}; \"\n",
    "                    \"qiime feature-classifier classify-consensus-vsearch --i-query {1} --o-classification \"\n",
    "                    \"{0}/rep_seqs_tax_assignments.qza --i-reference-reads {2} --i-reference-taxonomy {3} {5}; \"\n",
    "                    \"qiime tools export {0}/rep_seqs_tax_assignments.qza --output-dir {0}; \"\n",
    "                    \"mv {0}/taxonomy.tsv {0}/query_tax_assignments.txt\")\n",
    "        \n",
    "commands = parameter_sweep(data_dir, results_dir, reference_dbs,\n",
    "                           dataset_reference_combinations,\n",
    "                           method_parameters_combinations, command_template,\n",
    "                           infile='query.qza', output_name='rep_seqs_tax_assignments.qza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=23)(delayed(system)(command) for command in commands);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_parameters_combinations = {\n",
    "    'naive-bayes' : {'p-feat-ext--ngram-range': \n",
    "                     ['[4,4]', '[6,6]', '[8,8]', '[16,16]', '[32,32]',\n",
    "                      '[7,7]', '[9,9]', '[10,10]', '[11,11]', \n",
    "                      '[12,12]', '[14,14]', '[18,18]'],\n",
    "                     'p-classify--alpha': [0.001]},\n",
    "    'naive-bayes-bespoke' : {'p-feat-ext--ngram-range': \n",
    "                             ['[4,4]', '[6,6]', '[8,8]', '[16,16]', '[32,32]',\n",
    "                              '[7,7]', '[9,9]', '[10,10]', '[11,11]', \n",
    "                              '[12,12]', '[14,14]', '[18,18]'],\n",
    "                             'p-classify--alpha': [0.001],\n",
    "                             'p-classify--fit-prior': ['']}\n",
    "}\n",
    "\n",
    "command_template = ('mkdir -p \"{0}\"; '\n",
    "                    'qiime feature-classifier fit-classifier-naive-bayes --o-classifier '\n",
    "                    '\"{0}/classifier.qza\" --i-reference-reads {2} --i-reference-taxonomy {3} {5}; ')\n",
    "\n",
    "confidences = [0.0, 0.5, 0.7, 0.9, 0.92, 0.94,\n",
    "               0.96, 0.98, 1.0]\n",
    "command_template += ''.join(\n",
    "    'mkdir -p \"{0}:' + str(c) + '\"; '\n",
    "    'qiime feature-classifier classify-sklearn '\n",
    "    '--o-classification \"{0}:' + str(c) + '/rep_seqs_tax_assignments.qza\" '\n",
    "    '--i-classifier \"{0}/classifier.qza\" '\n",
    "    '--i-reads {1} --p-confidence ' + str(c) + '; '\n",
    "    'qiime tools export \"{0}:' + str(c) + '/rep_seqs_tax_assignments.qza\" --output-dir \"{0}:' + str(c) + '\"; '\n",
    "    'mv \"{0}:' + str(c) + '/taxonomy.tsv\" \"{0}:' + str(c) + '/query_tax_assignments.txt\"; 'for c in confidences)\n",
    "\n",
    "command_template += 'rm \"{0}/classifier.qza\"; rmdir \"{0}\"'\n",
    "\n",
    "commands = parameter_sweep(data_dir, results_dir, reference_dbs,\n",
    "                           dataset_reference_combinations,\n",
    "                           method_parameters_combinations, command_template,\n",
    "                           infile='query.qza', output_name='rep_seqs_tax_assignments.qza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2880 commands\n",
      "mkdir -p \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]\"\n",
      "\n",
      " qiime feature-classifier fit-classifier-naive-bayes --o-classifier \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\" --i-reference-reads ../../data/novel-taxa-simulations/B1-REF-L6-iter0/ref_seqs.qza --i-reference-taxonomy ../../data/novel-taxa-simulations/B1-REF-L6-iter0/ref_taxa.qza --p-classify--alpha 0.001 --p-feat-ext--ngram-range [4,4] --p-classify--fit-prior \n",
      "\n",
      " mkdir -p \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.0\"\n",
      "\n",
      " qiime feature-classifier classify-sklearn --o-classification \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.0/rep_seqs_tax_assignments.qza\" --i-classifier \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\" --i-reads ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.qza --p-confidence 0.0\n",
      "\n",
      " qiime tools export \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.0/rep_seqs_tax_assignments.qza\" --output-dir \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.0\"\n",
      "\n",
      " mv \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.0/taxonomy.tsv\" \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.0/query_tax_assignments.txt\"\n",
      "\n",
      " mkdir -p \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.5\"\n",
      "\n",
      " qiime feature-classifier classify-sklearn --o-classification \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.5/rep_seqs_tax_assignments.qza\" --i-classifier \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\" --i-reads ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.qza --p-confidence 0.5\n",
      "\n",
      " qiime tools export \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.5/rep_seqs_tax_assignments.qza\" --output-dir \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.5\"\n",
      "\n",
      " mv \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.5/taxonomy.tsv\" \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.5/query_tax_assignments.txt\"\n",
      "\n",
      " mkdir -p \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.7\"\n",
      "\n",
      " qiime feature-classifier classify-sklearn --o-classification \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.7/rep_seqs_tax_assignments.qza\" --i-classifier \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\" --i-reads ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.qza --p-confidence 0.7\n",
      "\n",
      " qiime tools export \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.7/rep_seqs_tax_assignments.qza\" --output-dir \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.7\"\n",
      "\n",
      " mv \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.7/taxonomy.tsv\" \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.7/query_tax_assignments.txt\"\n",
      "\n",
      " mkdir -p \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.9\"\n",
      "\n",
      " qiime feature-classifier classify-sklearn --o-classification \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.9/rep_seqs_tax_assignments.qza\" --i-classifier \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\" --i-reads ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.qza --p-confidence 0.9\n",
      "\n",
      " qiime tools export \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.9/rep_seqs_tax_assignments.qza\" --output-dir \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.9\"\n",
      "\n",
      " mv \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.9/taxonomy.tsv\" \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.9/query_tax_assignments.txt\"\n",
      "\n",
      " mkdir -p \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.92\"\n",
      "\n",
      " qiime feature-classifier classify-sklearn --o-classification \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.92/rep_seqs_tax_assignments.qza\" --i-classifier \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\" --i-reads ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.qza --p-confidence 0.92\n",
      "\n",
      " qiime tools export \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.92/rep_seqs_tax_assignments.qza\" --output-dir \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.92\"\n",
      "\n",
      " mv \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.92/taxonomy.tsv\" \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.92/query_tax_assignments.txt\"\n",
      "\n",
      " mkdir -p \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.94\"\n",
      "\n",
      " qiime feature-classifier classify-sklearn --o-classification \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.94/rep_seqs_tax_assignments.qza\" --i-classifier \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\" --i-reads ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.qza --p-confidence 0.94\n",
      "\n",
      " qiime tools export \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.94/rep_seqs_tax_assignments.qza\" --output-dir \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.94\"\n",
      "\n",
      " mv \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.94/taxonomy.tsv\" \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.94/query_tax_assignments.txt\"\n",
      "\n",
      " mkdir -p \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.96\"\n",
      "\n",
      " qiime feature-classifier classify-sklearn --o-classification \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.96/rep_seqs_tax_assignments.qza\" --i-classifier \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\" --i-reads ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.qza --p-confidence 0.96\n",
      "\n",
      " qiime tools export \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.96/rep_seqs_tax_assignments.qza\" --output-dir \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.96\"\n",
      "\n",
      " mv \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.96/taxonomy.tsv\" \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.96/query_tax_assignments.txt\"\n",
      "\n",
      " mkdir -p \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.98\"\n",
      "\n",
      " qiime feature-classifier classify-sklearn --o-classification \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.98/rep_seqs_tax_assignments.qza\" --i-classifier \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\" --i-reads ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.qza --p-confidence 0.98\n",
      "\n",
      " qiime tools export \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.98/rep_seqs_tax_assignments.qza\" --output-dir \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.98\"\n",
      "\n",
      " mv \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.98/taxonomy.tsv\" \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:0.98/query_tax_assignments.txt\"\n",
      "\n",
      " mkdir -p \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:1.0\"\n",
      "\n",
      " qiime feature-classifier classify-sklearn --o-classification \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:1.0/rep_seqs_tax_assignments.qza\" --i-classifier \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\" --i-reads ../../data/novel-taxa-simulations/B1-REF-L6-iter0/query.qza --p-confidence 1.0\n",
      "\n",
      " qiime tools export \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:1.0/rep_seqs_tax_assignments.qza\" --output-dir \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:1.0\"\n",
      "\n",
      " mv \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:1.0/taxonomy.tsv\" \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]:1.0/query_tax_assignments.txt\"\n",
      "\n",
      " rm \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]/classifier.qza\"\n",
      "\n",
      " rmdir \"../../novel-taxa-tmp/B1-REF-L6-iter0/B1-REF-L6-iter0/naive-bayes-bespoke/0.001::[4,4]\"\n"
     ]
    }
   ],
   "source": [
    "print(len(commands), 'commands')\n",
    "print('\\n\\n'.join(commands[0].split(';')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=23)(delayed(system)(command) for command in commands);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move result files to repository\n",
    "\n",
    "Add results to the tax-credit directory (e.g., to push these results to the repository or compare with other precomputed results in downstream analysis steps). The precomputed_results_dir path and methods_dirs glob below should not need to be changed unless if substantial changes were made to filepaths in the preceding cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precomputed_results_dir = join(project_dir, \"data\", \"precomputed-results\", analysis_name)\n",
    "method_dirs = glob(join(results_dir, '*', '*', '*', '*'))\n",
    "move_results_to_repository(method_dirs, precomputed_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
